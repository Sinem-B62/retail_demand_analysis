# -*- coding: utf-8 -*-
"""Woche 2 & 3.guayas_prepared.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Ox2ScJpH1fP7JgzmbqQr1YytUAieSxV

# **Ziel: Entwicklung eines ML-Modells zur Nachfrageprognose**
"""

!pip install -U gdown

import pandas as pd
import requests
import io


def make_drive_url(file_id):
    return f"https://drive.google.com/uc?id={file_id}"

# Hilfsfunktion zum Laden einer CSV-Datei Ã¼ber eine direkte URL
def load_csv_from_url(url):
    response = requests.get(url)
    response.raise_for_status()
    return pd.read_csv(io.StringIO(response.text))

    # Verzeichnis der Datei-IDs zur besseren Ãœbersichtlichkeit
file_ids = {
    "holiday_events": "1RMjSuqHXHTwAw_PGD5XVjhA3agaAGHDH",
    "items": "1ogMRixVhNY6XOJtIRtkRllyOyzw1nqya",
    "oil": "1Q59vk2v4WQ-Rpc9t2nqHcsZM3QWGFje_",
    "stores": "1Ei0MUXmNhmOcmrlPad8oklnFEDM95cDi",
    "train": "1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv",
    "transactions": "1PW5LnAEAiL43fI5CRDn_h6pgDG5rtBW_"
}

df_holiday_events = load_csv_from_url(make_drive_url(file_ids["holiday_events"]))
df_items          = load_csv_from_url(make_drive_url(file_ids["items"]))
df_oil            = load_csv_from_url(make_drive_url(file_ids["oil"]))
df_stores         = load_csv_from_url(make_drive_url(file_ids["stores"]))
df_transactions   = load_csv_from_url(make_drive_url(file_ids["transactions"]))

"""## **Datenanreicherung: Relevante Feiertage fÃ¼r Guayas integrieren**


"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

path = '/content/drive/MyDrive/Data Science Sinem/Time Series/df_train_filtered_top3_final.pkl'

df_train = pd.read_pickle(path)

print(f"âœ… Datei geladen: {len(df_train):,} Zeilen und {len(df_train.columns)} Spalten")
df_train.head()

guayas_cities = df_stores[df_stores['state'] == 'Guayas']['city'].unique()
print(f"âœ… Relevante StÃ¤dte in Guayas: {guayas_cities}")

"""Feiertage filtern: Zuerst wurden alle Feiertage (national, regional und lokal) herausgefiltert, die fÃ¼r die Provinz Guayas relevant sind. Diese wurden in einem separaten DataFrame (holiday_to_merge) zusammengefÃ¼hrt."""

df_holiday_events['type'].unique()

import gc

national_holidays = df_holiday_events[df_holiday_events['locale'] == 'National']
regional_holidays = df_holiday_events[df_holiday_events['locale_name'] == 'Guayas']
local_holidays = df_holiday_events[
    (df_holiday_events['locale'] == 'Local') &
    (df_holiday_events['locale_name'].isin(guayas_cities))
]

relevant_holidays = pd.concat([national_holidays, regional_holidays, local_holidays])
holiday_to_merge = relevant_holidays[['date', 'type']].drop_duplicates()

holiday_to_merge = holiday_to_merge.rename(columns={'type': 'holiday_type'})
print(f"  > {len(holiday_to_merge)} einzigartige FeiertagseintrÃ¤ge zum Mergen vorbereitet.")

"""Speicher freigeben Um den Arbeitsspeicher (RAM) zu schonen, wurden alle nicht mehr benÃ¶tigten, temporÃ¤ren DataFrames (z.B. die ursprÃ¼nglichen Feiertagslisten) gelÃ¶scht."""

del df_stores
del df_holiday_events
del national_holidays, regional_holidays, local_holidays, relevant_holidays
gc.collect()

"""Daten mergen (verbinden) Die gefilterten Feiertagsdaten wurden Ã¼ber die Datum-Spalte mit dem Haupt-Trainingsdatensatz (df_train) verbunden. Das Ergebnis ist ein neues DataFrame (df_train_final), das nun eine zusÃ¤tzliche Spalte fÃ¼r den Feiertagstyp (holiday_type) enthÃ¤lt."""

df_train['date'] = pd.to_datetime(df_train['date'])
holiday_to_merge['date'] = pd.to_datetime(holiday_to_merge['date'])

df_train_final = df_train.merge(
    holiday_to_merge,
    on='date',
    how='left'
)

del df_train
del holiday_to_merge
gc.collect()
print("  > Merge erfolgreich. 'df_train' aus RAM gelÃ¶scht.")

"""Daten bereinigen und optimieren Tage, die keine Feiertage sind, hatten nach dem Mergen einen NaN-Wert (Missing Value). Diese LÃ¼cken wurden mit dem Platzhalter "kein bestimmtes Ereignis" gefÃ¼llt. AnschlieÃŸend wurde die Spalte holiday_type in den speichereffizienten Datentyp category umgewandelt."""

df_train_final['holiday_type'] = df_train_final['holiday_type'].fillna('Kein bestimmtes Ereignis')

df_train_final['holiday_type'] = df_train_final['holiday_type'].astype('category')

print("\n--- âœ… FERTIG! ---")
print("Speicherverbrauch des finalen DataFrames 'df_train_final':")
df_train_final.info()

print("\nErgebnis (Alle Typen sind enthalten):")
print(df_train_final['holiday_type'].value_counts())

df_train_final

"""# **Filterung auf die Top-3-Familien**

Um die Analyse gezielt auf die wichtigsten Produktgruppen zu konzentrieren, wird der Datensatz auf die drei hÃ¤ufigsten Familien â€GROCERY Iâ€œ, â€BEVERAGESâ€œ und â€CLEANINGâ€œ eingeschrÃ¤nkt.
"""

df_items

top_families = ['GROCERY I', 'BEVERAGES', 'CLEANING']

item_ids = df_items[df_items['family'].isin(top_families)]['item_nbr'].unique()

df_train_final = df_train_final[df_train_final['item_nbr'].isin(item_ids)]

print(f"âœ… Gefilterte Daten (nur Top-3): {len(df_train_final):,} Zeilen")

df_train_final = df_train_final.merge(df_items[['item_nbr', 'family']], on='item_nbr', how='left')
print("\nVerteilung der Zeilen auf die Familien im gefilterten Set:")
df_train_final

"""# Der Datensatz wird auf das erste Quartal 2014 **(1. Januar bis 31. MÃ¤rz)** begrenzt, um einen Ã¼berschaubaren Zeitraum fÃ¼r das Modelltraining zu verwenden."""

# Zeitraum definieren
start_date = '2014-01-01'
end_date = '2014-03-31'

df_train_final = df_train_final[
    (df_train_final['date'] >= start_date) &
    (df_train_final['date'] <= end_date)
]

df_train_final

"""## Im Rahmen des Feature Engineerings werden zeitbasierte Merkmale (Jahr, Monat, Wochentag), Lag-Features und gleitende Durchschnitte erstellt, um Trends und saisonale Effekte fÃ¼r XGBoost sichtbar zu machen."""

# Lag-Features (VerzÃ¶gerungen) erstellen â€” vergangene Verkaufswerte
df_train_final = df_train_final.sort_values(['store_nbr', 'item_nbr', 'date'])

df_train_final['lag_1'] = df_train_final['unit_sales'].shift(1)
df_train_final['lag_7'] = df_train_final['unit_sales'].shift(7)
df_train_final['lag_30'] = df_train_final['unit_sales'].shift(30)


df_train_final['rolling_std_7'] = df_train_final['unit_sales'].shift(1).rolling(window=7).std()

# Fehlende Werte nach Shifts auffÃ¼llen
cols_to_fill = ['lag_1', 'lag_7', 'lag_30', 'rolling_std_7']
df_train_final[cols_to_fill] = df_train_final[cols_to_fill].fillna(0)

df_train_final = df_train_final.set_index('date')

# Kontrolle
print("âœ… Neue Features hinzugefÃ¼gt:")
print(df_train_final.columns)
df_train_final

print(f"Spalten VOR get_dummies: {len(df_train_final.columns)}")
print(df_train_final.dtypes)


df_train_final = pd.get_dummies(
    df_train_final,
    columns=['holiday_type', 'family'],
    drop_first=True
)

print(f"\nSpalten NACH get_dummies: {len(df_train_final.columns)}")
print("--- DataFrame ist jetzt bereit fÃ¼r das Modell ---")
df_train_final.head()

"""# **Aufteilung Training/Test**"""

import pandas as pd

# Datum sicherstellen
df_train_final.index = pd.to_datetime(df_train_final.index)
df_train_final = df_train_final.sort_index()

# ZeitrÃ¤ume festlegen
train_start = '2014-01-01'
train_end   = '2014-02-28'
test_start  = '2014-03-01'
test_end    = '2014-03-31'

# Masken auf Basis des Index erstellen
train_mask = (df_train_final.index >= train_start) & (df_train_final.index <= train_end)
test_mask  = (df_train_final.index >= test_start)  & (df_train_final.index <= test_end)

# Daten filtern
df_train = df_train_final.loc[train_mask]
df_test  = df_train_final.loc[test_mask]

# Kontrolle
print("âœ… Trainingsdaten:", len(df_train),
      "Zeilen von", df_train.index.min(), "bis", df_train.index.max())

print("âœ… Testdaten:", len(df_test),
      "Zeilen von", df_test.index.min(), "bis", df_test.index.max())

target_col = 'unit_sales'

feature_cols = [
    'store_nbr',
    'item_nbr',
    'onpromotion',
    'z_score',
    'year',
    'month',
    'day_of_week',
    'unit_sales_7d_avg',
    'lag_1',
    'lag_7',
    'lag_30',
    'rolling_std_7',
    'holiday_type_Bridge',
    'holiday_type_Event',
    'holiday_type_Holiday',
    'holiday_type_Kein bestimmtes Ereignis',
    'holiday_type_Transfer',
    'holiday_type_Work Day',
    'family_CLEANING',
    'family_GROCERY I'
]

# Trainingsdaten trennen
X_train = df_train[feature_cols]
y_train = df_train[target_col]

# ğŸ”¹ Testdaten trennen
X_test = df_test[feature_cols]
y_test = df_test[target_col]

# Kontrolle
print("Feature-Matrix (Train):", X_train.shape)
print("Target (Train):", y_train.shape)
print("Feature-Matrix (Test):", X_test.shape)
print("Target (Test):", y_test.shape)

"""# **XGBoost-Modellaufbau**
zur Vorhersage von numerischen Werten in dem Fall Verkaufszahlen

## XGBoost-Baseline

n_estimators=250 = Anzahl der BÃ¤ume:
Das Modell besteht aus 250 EntscheidungsbÃ¤umen. Mehr BÃ¤ume = stÃ¤rkeres Modell (aber langsamer).

learning_rate=0.1 = Lernrate:
Wie stark jeder neue Baum die Gesamtvorhersage korrigiert. Kleinere Werte lernen langsamer, aber stabiler.


max_depth=7 = Maximale Tiefe der BÃ¤ume:
Wie viele â€Fragenâ€œ ein Baum stellen darf. Tiefer = komplexer, aber riskanter (Overfitting).

random_state=42 = Zufallsstartwert:
Damit die Ergebnisse reproduzierbar bleiben.

n_jobs=-1 = Anzahl der Prozessorkerne:
-1 bedeutet: benutze alle verfÃ¼gbaren Kerne, um schneller zu rechnen.
"""

from xgboost import XGBRegressor

model = XGBRegressor(
    n_estimators=250,
    learning_rate=0.1,
    max_depth=7,
    random_state=42,
    n_jobs=-1
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("âœ… Modell trainiert! Anzahl Vorhersagen:", len(y_pred))

import matplotlib.pyplot as plt

daily_sales = df_train_final[['unit_sales', 'unit_sales_7d_avg', 'rolling_std_7']].resample('D').mean()

plt.figure(figsize=(20, 8))
plt.plot(daily_sales.index, daily_sales['unit_sales'], label='unit_sales', color='black',linewidth=1, alpha=0.7)
plt.plot(daily_sales.index, daily_sales['unit_sales_7d_avg'], label='unit_sales_7d_avg', linewidth=2,  color='blue')
plt.plot(daily_sales.index, daily_sales['rolling_std_7'], label='rolling_std_7', linewidth=2,  color='magenta')
plt.title('Original Sales, 7-day Rolling Mean, and 7-day Rolling Std Dev')
plt.xlabel('Datum')
plt.ylabel('VerkÃ¤ufe')
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error

y_pred = pd.Series(y_pred, index=y_test.index)

print("LÃ¤nge y_test:", len(y_test))
print("LÃ¤nge y_pred:", len(y_pred))


mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

print(f"Mean Absolut Error : {mae:.4f} units: Das Modell sagt sehr nah an den echten Werten voraus.")
print(f"Mean Squared Error : {mse:.4f} units: Es gibt einzelne grÃ¶ÃŸere Fehler, aber insgesamt ist das Modell stabil.")

"""## Bewertung meiner XGBoost-Baseline

Der gezeigte Code definiert eine Funktion zur Bewertung der Modellleistung anhand typischer Prognosemetriken.
Mit der Funktion forecast_metrics(y_true, y_pred) werden wichtige Kennzahlen berechnet, die zeigen, wie gut das XGBoost-Modell die Verkaufszahlen vorhersagt.

Dazu gehÃ¶ren:

- MAE (Mean Absolute Error): durchschnittlicher absoluter Fehler â€“ misst die Genauigkeit.

- Bias: zeigt, ob das Modell systematisch Ã¼ber- oder unterschÃ¤tzt.

- MAD / rMAD: mittlere absolute Abweichung und deren relatives VerhÃ¤ltnis.

- MAPE (Mean Absolute Percentage Error): prozentuale Abweichung der Vorhersagen vom tatsÃ¤chlichen Wert.

- RMSE (Root Mean Squared Error): gibt stÃ¤rkere Gewichtung auf grÃ¶ÃŸere Fehler.

Diese Metriken sind entscheidend, um die QualitÃ¤t eines Prognosemodells objektiv zu bewerten.
Sie ermÃ¶glichen es, StÃ¤rken und SchwÃ¤chen des Modells zu erkennen und bilden die Grundlage fÃ¼r die spÃ¤tere Optimierung des XGBoost-Modells.

Der Code liefert den ersten, quantitativen Beweis, wie zuverlÃ¤ssig deine Baseline-Vorhersage wirklich ist â€“ ein essenzieller Schritt im gesamten Machine-Learning-Projekt.
"""

import numpy as np

def forecast_metrics(y_true, y_pred):
    """
    Compute a common set of forecast-error statistics.

    Parameters
    ----------
    y_true : 1-D array-like
        Actual (ground-truth) values.
    y_pred : 1-D array-like
        Forecasted values.

    Returns
    -------
    dict
        Keys: 'MAE', 'Bias', 'MAD', 'rMAD', 'MAPE', 'RMSE'
    """
    y_true = np.asarray(y_true, dtype=float).flatten()
    y_pred = np.asarray(y_pred, dtype=float).flatten()

    errors       = y_true - y_pred
    abs_errors   = np.abs(errors)
    pct_errors   = abs_errors / np.where(y_true == 0, np.nan, y_true)

    mae   = abs_errors.mean()
    bias  = errors.mean()
    rmse  = np.sqrt((errors ** 2).mean())

    mad   = np.abs(y_true - y_true.mean()).mean()

    rmad  = mae / mad if mad else np.nan

    mape  = np.nanmean(pct_errors) * 100

    return {
        "MAE" : mae,
        "Bias": bias,
        "MAD" : mad,
        "rMAD": rmad,
        "MAPE": mape,
        "RMSE": rmse
    }

metrics = forecast_metrics(y_test, y_pred)
for k, v in metrics.items():
    print(f"{k}: {v:,.2f}")

"""## Optimierung von XGBoost-Baseline: Hyperparamtertuning

In diesem Abschnitt wird die LeistungsfÃ¤higkeit des XGBoost-Modells durch gezieltes Hyperparametertuning verbessert.
Anstatt feste Parameter zu verwenden, wird hier mit einer RandomizedSearchCV eine Vielzahl mÃ¶glicher Parameterkombinationen getestet, um jene Konfiguration zu finden, die den niedrigsten Fehler (RMSE) erzielt.

**Vorgehen:**

Parameterraum definieren:
Es werden verschiedene Wertebereiche fÃ¼r wichtige Parameter festgelegt, z. B.

- learning_rate: Lernrate des Modells

- max_depth: maximale Baumtiefe

- subsample & colsample_bytree: Anteil der Daten und Features pro Baum

- n_estimators: Anzahl der EntscheidungsbÃ¤ume

Zeitreihen-Cross-Validation (TimeSeriesSplit):
Da es sich um Zeitreihendaten handelt, wird eine spezielle Validierung verwendet, die den zeitlichen Verlauf respektiert â€“ das verhindert Datenleckagen.

RandomizedSearchCV:
Diese Methode wÃ¤hlt zufÃ¤llig Kombinationen aus dem Parameterraster aus und testet sie, um die besten Parameter effizient zu finden (schneller als GridSearchCV).

Trainieren & Bewerten:
Mit den optimalen Parametern wird das finale Modell neu trainiert und anhand der zuvor definierten Metriken (MAE, RMSE, MAPE usw.) bewertet.

Visualisierung:
Die grafische Darstellung zeigt die tatsÃ¤chlichen Verkaufszahlen im Vergleich zu den vorhergesagten Werten â€” ein wichtiger Schritt zur visuellen Bewertung der ModellqualitÃ¤t.
"""

from xgboost import XGBRegressor
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV

xgb = XGBRegressor(objective='reg:squarederror')

# Definition von Parameterraster
param_grid = {
    'learning_rate': [0.01, 0.1, 0.3],
    'max_depth': [3, 5, 7],
    'subsample': [0.6, 0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0],
    'n_estimators': [100, 200, 300, 500]
}

tscv = TimeSeriesSplit()

random_search = RandomizedSearchCV(estimator=xgb,
																	 param_distributions=param_grid,
                                   cv=tscv,
                                   n_iter=10,
                                   scoring='neg_mean_squared_error')

random_search.fit(X_train, y_train)

best_params = random_search.best_params_
print("Best Parameters for XGBoost:", best_params)

final_model = XGBRegressor(
    objective='reg:squarederror',
    n_estimators=best_params["n_estimators"],
    max_depth=best_params["max_depth"],
    learning_rate=best_params["learning_rate"],
    subsample=best_params["subsample"],
    colsample_bytree=best_params["colsample_bytree"],
    random_state=42
)

# Train the model
final_model.fit(X_train, y_train)

# Make predictions
y_pred = final_model.predict(X_test)

metrics = forecast_metrics(y_test, y_pred)
for k, v in metrics.items():
    print(f"{k}: {v:,.2f}")

df_plot = pd.DataFrame({
    'Actual': y_test,
    'Predicted': y_pred
})

df_daily_plot = df_plot.resample('D').sum()

plt.figure(figsize=(15, 6))
plt.plot(df_daily_plot['Actual'], label='TatsÃ¤chliche GesamtverkÃ¤ufe')
plt.plot(df_daily_plot['Predicted'], label='Vorhergesagte GesamtverkÃ¤ufe', linestyle='--')
plt.legend()
plt.title('TÃ¤gliche Gesamtprognose vs. RealitÃ¤t (MÃ¤rz 2014)')
plt.ylabel('Summe der verkauften Einheiten')
plt.show()

plt.figure(figsize=(10, 8))

max_val = y_test.max()
plt.plot([0, max_val], [0, max_val], 'r--', label='Perfekte Prognose (y=x)')

plt.scatter(y_test, y_pred, alpha=0.3, label='Modellprognose')

plt.xlabel('TatsÃ¤chliche VerkÃ¤ufe (Actual)')
plt.ylabel('Vorhergesagte VerkÃ¤ufe (Predicted)')
plt.title('Streudiagramm: PrognosequalitÃ¤t')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
from xgboost import plot_importance

fig, ax = plt.subplots(figsize=(10, 8))
plot_importance(final_model, ax=ax)
plt.show()

"""## MLflow-Setup fÃ¼r XGBoost

In diesem Abschnitt wird MLflow genutzt, um das Training und die Bewertung des XGBoost-Modells automatisch zu protokollieren.
Alle wichtigen Informationen â€“ wie Parameter, Metriken, Modelle und Diagramme â€“ werden gespeichert, damit die Experimente vergleichbar und reproduzierbar bleiben.

Der Code:

- erstellt ein MLflow-Experiment (XGBoost_Basislinie),

- trainiert das Modell und berechnet Prognosemetriken,

- speichert alle Ergebnisse und das Modell direkt in MLflow.

So wird sichergestellt, dass jede Modellversion dokumentiert ist und spÃ¤ter leicht verglichen oder erneut geladen werden kann.
Ein zentraler Schritt fÃ¼r Nachvollziehbarkeit und sauberes Experiment-Tracking.
"""

!pip install mlflow

# MLflow-Setup fÃ¼r XGBoost-Basislinie

import mlflow
import mlflow.xgboost
import matplotlib.pyplot as plt
import numpy as np
from xgboost import XGBRegressor

# MLflow Setup
mlflow.set_experiment("XGBoost_Basislinie")  # Name des Experiments

# Rahmenparameter definiert
baseline_params = {
    "n_estimators": 250,
    "learning_rate": 0.1,
    "max_depth": 7,
    "random_state": 42,
    "n_jobs": -1,
    "objective": "reg:squarederror"
}

# Start meines 1. Laufs
with mlflow.start_run(run_name="Basis-XGB"):

    # Modellaufbau & Training
    model = XGBRegressor(**baseline_params)
    model.fit(X_train, y_train)

    # Vorhersagen
    y_pred = model.predict(X_test)

    # Metriken berechnen
    metrics = forecast_metrics(y_test, y_pred)

    # Parameter & Metriken in MLflow speichern
    mlflow.log_params(baseline_params)
    mlflow.log_metrics({k: float(v) for k, v in metrics.items()})

    # Prognose-Diagramm erstellen
    plt.figure(figsize=(8, 5))
    plt.plot(y_test, label="Wahre Werte", color="blue")
    plt.plot(y_pred, label="Vorhersage", color="orange")
    plt.title("XGBoost-Basislinie: Wahre Werte vs. Vorhersage")
    plt.xlabel("Zeitindex")
    plt.ylabel("Verkaufswert")
    plt.legend()
    plt.tight_layout()

    # Diagramm speichern und als Artefakt hochladen
    plt.savefig("forecast_plot.png")
    mlflow.log_artifact("forecast_plot.png")
    plt.close()

    # Modell selbst speichern
    mlflow.xgboost.log_model(model, artifact_path="xgb_model_baseline")

    # Tags setzen
    mlflow.set_tag("stage", "baseline")
    mlflow.set_tag("model_type", "XGBoost")

    print("âœ… MLflow-Basislauf abgeschlossen!")
    print("ğŸ” Ergebnisse im MLflow-UI anzeigen mit:  mlflow ui")

import mlflow
import pandas as pd

# Dein Experiment-Name aus dem Code
exp_name = "XGBoost_Basislinie"

# Experiment-ID holen
exp = mlflow.get_experiment_by_name(exp_name)

# Alle Runs als DataFrame ziehen
runs_df = mlflow.search_runs(
    experiment_ids=[exp.experiment_id],
    output_format="pandas"
)

# Nur die wichtigsten Spalten zeigen
cols = [
    "run_id", "tags.stage", "params.n_estimators", "params.learning_rate",
    "params.max_depth", "metrics.MAE", "metrics.RMSE", "metrics.MAPE"
]
display(runs_df[cols].sort_values("metrics.RMSE"))

"""2. Lauf â€“ MLflow fÃ¼r optimiertes XGBoost-Modell"""

import mlflow
import matplotlib.pyplot as plt
from xgboost import XGBRegressor

# Zweiter MLflow-Lauf: Optimiertes Modell
with mlflow.start_run(run_name="Optimiertes-XGB"):

    # Trainiere Modell mit den besten Parametern aus RandomizedSearchCV
    optimized_model = XGBRegressor(
        objective='reg:squarederror',
        n_estimators=best_params["n_estimators"],
        max_depth=best_params["max_depth"],
        learning_rate=best_params["learning_rate"],
        subsample=best_params["subsample"],
        colsample_bytree=best_params["colsample_bytree"],
        random_state=42
    )

    optimized_model.fit(X_train, y_train)
    y_pred_opt = optimized_model.predict(X_test)

    # Berechne Metriken
    metrics_opt = forecast_metrics(y_test, y_pred_opt)

    # Logge Parameter und Metriken in MLflow
    mlflow.log_params(best_params)
    mlflow.log_metrics(metrics_opt)

    # Erstelle Vergleichsdiagramm (tatsÃ¤chliche vs. vorhergesagte Werte)
    plt.figure(figsize=(8, 5))
    plt.plot(y_test.values[:200], label="Wahre Werte", color="blue")
    plt.plot(y_pred_opt[:200], label="Optimierte Vorhersage", color="green")
    plt.title("Optimiertes XGBoost-Modell: Wahr vs. Vorhergesagt")
    plt.xlabel("Zeitindex")
    plt.ylabel("Verkaufswert")
    plt.legend()
    plt.tight_layout()
    plt.savefig("optimized_forecast_plot.png")

    # Logge Diagramm und Modell
    mlflow.log_artifact("optimized_forecast_plot.png")
    mlflow.xgboost.log_model(optimized_model, artifact_path="xgb_model_optimized")

    # Setze Tags (optional, fÃ¼r Ãœbersicht)
    mlflow.set_tag("stage", "optimized")
    mlflow.set_tag("model_type", "XGBoost")

    print("âœ… Zweiter MLflow-Lauf abgeschlossen! (Optimiertes Modell)")

"""## ğŸ“ŠVergleich Baseline vs. Optimiertes Modell: XGBoost

In diesem Schritt werden die Ergebnisse des Basismodells und des optimierten XGBoost-Modells direkt miteinander verglichen.
Dazu werden die gespeicherten MLflow-Runs geladen und die wichtigsten Metriken (z. B. RMSE, MAE, MAPE) ausgewertet.

Die Balkengrafik zeigt die Unterschiede in der Modellleistung auf einen Blick â€“ insbesondere beim RMSE-Wert, der die Prognosegenauigkeit misst.
So lÃ¤sst sich leicht erkennen, ob das Tuning tatsÃ¤chlich zu einer Verbesserung der VorhersagequalitÃ¤t gefÃ¼hrt hat.

Ein wichtiger Schritt, um den Erfolg des Modelltrainings objektiv zu bewerten.
"""

import pandas as pd

# Experiment-Name aus deinen Runs
exp_name = "XGBoost_Basislinie"

# Experiment-ID holen
exp = mlflow.get_experiment_by_name(exp_name)

# Alle Runs laden
runs_df = mlflow.search_runs(
    experiment_ids=[exp.experiment_id],
    output_format="pandas"
)

# Nur wichtige Spalten anzeigen
cols = [
    "tags.stage",
    "params.n_estimators",
    "params.learning_rate",
    "params.max_depth",
    "metrics.MAE",
    "metrics.RMSE",
    "metrics.MAPE"
]

comparison_df = runs_df[cols].sort_values("metrics.RMSE").reset_index(drop=True)
display(comparison_df)

"""### Visuelle GegenÃ¼berstellung (Barplot der Metriken)"""

# Leere Werte in der Spalte "tags.stage" ersetzen
comparison_df["tags.stage"] = comparison_df["tags.stage"].fillna("unknown")

# Dann plotten
plt.figure(figsize=(8, 5))
plt.bar(comparison_df["tags.stage"], comparison_df["metrics.RMSE"], color=["orange", "green"])
plt.title("Vergleich: RMSE Baseline vs. Optimiert")
plt.ylabel("RMSE")
plt.xlabel("Modell")
plt.show()

"""In diesem Schritt wird aus allen gespeicherten MLflow-Runs automatisch das Modell mit dem besten RMSE-Wert ermittelt â€“ also jenes, das die genauesten Vorhersagen liefert.

Der Code durchsucht die gespeicherten Ergebnisse, gibt die beste Run-ID aus und lÃ¤dt das entsprechende Modell direkt aus MLflow.
Dadurch kannst du das leistungsstÃ¤rkste Modell jederzeit wiederverwenden, ohne es neu trainieren zu mÃ¼ssen.

Ein wichtiger Schritt fÃ¼r Effizienz und Nachvollziehbarkeit im Modellmanagement.
"""

import mlflow
import mlflow.xgboost
import pandas as pd

# Name deines MLflow-Experiments
exp_name = "XGBoost_Basislinie"

# Experiment holen
exp = mlflow.get_experiment_by_name(exp_name)

# Alle Runs abrufen
runs_df = mlflow.search_runs(
    experiment_ids=[exp.experiment_id],
    output_format="pandas"
)

# Besten Run anhand des niedrigsten RMSE finden
best_run = runs_df.loc[runs_df["metrics.RMSE"].idxmin()]
best_run_id = best_run["run_id"]

print("ğŸ† Bestes Modell gefunden!")
print(f"Stage: {best_run['tags.stage']}")
print(f"RMSE: {best_run['metrics.RMSE']:.4f}")
print(f"Run-ID: {best_run_id}")

model_uri = f"runs:/{best_run_id}/xgb_model_optimized"

# Der Rest bleibt gleich
best_model = mlflow.xgboost.load_model(model_uri)
print("âœ… Modell erfolgreich geladen!")

"""# Feature-Spalten als Artefakt speichern"""

import json
import os

# Beispiel: deine verwendeten Feature-Spalten
feature_columns = [
    "store_nbr", "item_nbr", "onpromotion", "z_score",
    "year", "month", "day_of_week", "unit_sales_7d_avg"
]

# Erstelle einen Artefakt-Ordner, falls er noch nicht existiert
os.makedirs("artifacts", exist_ok=True)

# Speichere die Feature-Spalten als JSON-Datei
with open("artifacts/feature_columns.json", "w") as f:
    json.dump(feature_columns, f)

print("âœ… Feature-Spalten erfolgreich als JSON-Artefakt gespeichert!")
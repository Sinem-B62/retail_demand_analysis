{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ui6VpGcAyjss",
        "jCP24aU_v3g8",
        "dIuhPJrQujSZ",
        "rXNJ0YERuxmd",
        "V4i40aSgw-wD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Ziel: Entwicklung eines ML-Modells zur Nachfrageprognose**"
      ],
      "metadata": {
        "id": "fnfBZzsc1rqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "\n",
        "def make_drive_url(file_id):\n",
        "    return f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Hilfsfunktion zum Laden einer CSV-Datei über eine direkte URL\n",
        "def load_csv_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return pd.read_csv(io.StringIO(response.text))\n",
        "\n",
        "    # Verzeichnis der Datei-IDs zur besseren Übersichtlichkeit\n",
        "file_ids = {\n",
        "    \"holiday_events\": \"1RMjSuqHXHTwAw_PGD5XVjhA3agaAGHDH\",\n",
        "    \"items\": \"1ogMRixVhNY6XOJtIRtkRllyOyzw1nqya\",\n",
        "    \"oil\": \"1Q59vk2v4WQ-Rpc9t2nqHcsZM3QWGFje_\",\n",
        "    \"stores\": \"1Ei0MUXmNhmOcmrlPad8oklnFEDM95cDi\",\n",
        "    \"train\": \"1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv\",\n",
        "    \"transactions\": \"1PW5LnAEAiL43fI5CRDn_h6pgDG5rtBW_\"\n",
        "}\n",
        "\n",
        "df_holiday_events = load_csv_from_url(make_drive_url(file_ids[\"holiday_events\"]))\n",
        "df_items          = load_csv_from_url(make_drive_url(file_ids[\"items\"]))\n",
        "df_oil            = load_csv_from_url(make_drive_url(file_ids[\"oil\"]))\n",
        "df_stores         = load_csv_from_url(make_drive_url(file_ids[\"stores\"]))\n",
        "df_transactions   = load_csv_from_url(make_drive_url(file_ids[\"transactions\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZlahpvAsd7Gh",
        "outputId": "4817a059-ad0d-4602-ecc8-090c523b3251"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Überprüfung der Region - Guayas**\n",
        "\n",
        "Der Datensatz wurde mit den Filialinformationen verknüpft, um sicherzustellen, dass alle Einträge aus der Provinz Guayas stammen."
      ],
      "metadata": {
        "id": "W-FHijVfuWGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUGl6eXhCMs_",
        "outputId": "b9b4a77e-3963-4b99-90d7-f9426bf4b355"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/MyDrive/Data Science Sinem/Time Series/df_train_filtered_top3_final.pkl'\n",
        "\n",
        "df_train = pd.read_pickle(path)\n",
        "\n",
        "print(f\"✅ Datei geladen: {len(df_train):,} Zeilen und {len(df_train.columns)} Spalten\")\n",
        "df_train.head()\n"
      ],
      "metadata": {
        "id": "rkV7iw16tnjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_stores.columns)\n"
      ],
      "metadata": {
        "id": "Z_TQs3HItxLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verknüpfen der Verkaufsdaten mit den Filialinformationen\n",
        "df_merged = df_train.merge(df_stores[['store_nbr', 'state']], on='store_nbr', how='left')\n",
        "\n",
        "print(f\"✅ Nach Merge: {len(df_merged):,} Zeilen, {len(df_merged.columns)} Spalten\")\n",
        "df_merged.head()\n"
      ],
      "metadata": {
        "id": "dSLR3Wf6tzzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_merged['state'].value_counts())\n"
      ],
      "metadata": {
        "id": "PouysMvDt4A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filterung auf die Top-3-Familien**\n",
        "\n",
        "Um die Analyse gezielt auf die wichtigsten Produktgruppen zu konzentrieren, wird der Datensatz auf die drei häufigsten Familien „GROCERY I“, „BEVERAGES“ und „CLEANING“ eingeschränkt."
      ],
      "metadata": {
        "id": "_I3VJeRluzEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_items"
      ],
      "metadata": {
        "id": "1Gjr36a0vZ6j",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definieren der Top-3-Familien\n",
        "top_families = ['GROCERY I', 'BEVERAGES', 'CLEANING']\n",
        "\n",
        "item_ids = df_items[df_items['family'].isin(top_families)]['item_nbr'].unique()\n",
        "\n",
        "# Trainingsdaten filtern\n",
        "df_train_filtered = df_train[df_train['item_nbr'].isin(item_ids)]\n",
        "\n",
        "# Kontrolle\n",
        "print(f\"✅ Gefilterte Daten: {len(df_train_filtered):,} Zeilen\")\n",
        "print(df_items['family'].value_counts())\n"
      ],
      "metadata": {
        "id": "rdFpUvFgu4Ke",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_filtered"
      ],
      "metadata": {
        "id": "Hnih6ud9vVmA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Der Datensatz wird auf das erste Quartal 2014 **(1. Januar bis 31. März)** begrenzt, um einen überschaubaren Zeitraum für das Modelltraining zu verwenden."
      ],
      "metadata": {
        "id": "eVqHf6mTwrnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeitraum definieren\n",
        "start_date = '2014-01-01'\n",
        "end_date = '2014-03-31'\n",
        "\n",
        "df_train_filtered = df_train_filtered[\n",
        "    (df_train_filtered['date'] >= start_date) &\n",
        "    (df_train_filtered['date'] <= end_date)\n",
        "]"
      ],
      "metadata": {
        "id": "-AxwAoXgweW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_filtered"
      ],
      "metadata": {
        "id": "EUrxvG3mwjQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Im Rahmen des Feature Engineerings werden zeitbasierte Merkmale (Jahr, Monat, Wochentag), Lag-Features und gleitende Durchschnitte erstellt, um Trends und saisonale Effekte für XGBoost sichtbar zu machen."
      ],
      "metadata": {
        "id": "Lcrq7Vd7xow2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lag-Features (Verzögerungen) erstellen — vergangene Verkaufswerte\n",
        "df_train_filtered = df_train_filtered.sort_values(['store_nbr', 'item_nbr', 'date'])\n",
        "\n",
        "df_train_filtered['lag_1'] = df_train_filtered['unit_sales'].shift(1)\n",
        "df_train_filtered['lag_7'] = df_train_filtered['unit_sales'].shift(7)\n",
        "df_train_filtered['lag_30'] = df_train_filtered['unit_sales'].shift(30)\n",
        "\n",
        "\n",
        "df_train_filtered['rolling_std_7'] = df_train_filtered['unit_sales'].shift(1).rolling(window=7).std()\n",
        "\n",
        "# Fehlende Werte nach Shifts auffüllen (optional)\n",
        "df_train_filtered = df_train_filtered.fillna(0)\n",
        "\n",
        "df_train_filtered = df_train_filtered.set_index('date')\n",
        "\n",
        "# Kontrolle\n",
        "print(\"✅ Neue Features hinzugefügt:\")\n",
        "print(df_train_filtered.columns)\n",
        "df_train_filtered"
      ],
      "metadata": {
        "id": "ym7va-B0xWve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = df_train_filtered.merge(df_stores, on='store_nbr', how='left')\n",
        "\n",
        "df_merged = df_merged.merge(df_items, on='item_nbr', how='left')\n",
        "\n",
        "print(\"✅ Daten erfolgreich zusammengeführt!\")\n",
        "print(f\"➡️ Zeilen: {len(df_merged):,}\")\n",
        "print(f\"➡️ Spalten: {len(df_merged.columns)}\")\n",
        "print(\"\\n🧠 Neue Spaltenbeispiele:\")\n",
        "print(df_merged.columns.tolist()[:15])  # Zeigt die ersten Spaltennamen\n",
        "print(\"\\n📊 Stichprobe:\")\n",
        "display(df_merged.head(3))\n"
      ],
      "metadata": {
        "id": "diXk6-P5yNYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aufteilung Training/Test**"
      ],
      "metadata": {
        "id": "Ui6VpGcAyjss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Datum sicherstellen\n",
        "df_train_filtered.index = pd.to_datetime(df_train_filtered.index)\n",
        "df_train_filtered = df_train_filtered.sort_index()\n",
        "\n",
        "# Zeiträume festlegen\n",
        "train_start = '2014-01-01'\n",
        "train_end   = '2014-02-28'\n",
        "test_start  = '2014-03-01'\n",
        "test_end    = '2014-03-31'\n",
        "\n",
        "# Masken auf Basis des Index erstellen\n",
        "train_mask = (df_train_filtered.index >= train_start) & (df_train_filtered.index <= train_end)\n",
        "test_mask  = (df_train_filtered.index >= test_start)  & (df_train_filtered.index <= test_end)\n",
        "\n",
        "# Daten filtern\n",
        "df_train = df_train_filtered.loc[train_mask]\n",
        "df_test  = df_train_filtered.loc[test_mask]\n",
        "\n",
        "# Kontrolle\n",
        "print(\"✅ Trainingsdaten:\", len(df_train),\n",
        "      \"Zeilen von\", df_train.index.min(), \"bis\", df_train.index.max())\n",
        "\n",
        "print(\"✅ Testdaten:\", len(df_test),\n",
        "      \"Zeilen von\", df_test.index.min(), \"bis\", df_test.index.max())\n"
      ],
      "metadata": {
        "id": "toV1Vtrv2fDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'unit_sales'\n",
        "\n",
        "feature_cols = [\n",
        "    'store_nbr',\n",
        "    'item_nbr',\n",
        "    'onpromotion',\n",
        "    'z_score',\n",
        "    'year',\n",
        "    'month',\n",
        "    'day_of_week',\n",
        "    'unit_sales_7d_avg'\n",
        "]\n",
        "\n",
        "# Trainingsdaten trennen\n",
        "X_train = df_train[feature_cols]\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "# 🔹 Testdaten trennen\n",
        "X_test = df_test[feature_cols]\n",
        "y_test = df_test[target_col]\n",
        "\n",
        "# Kontrolle\n",
        "print(\"Feature-Matrix (Train):\", X_train.shape)\n",
        "print(\"Target (Train):\", y_train.shape)\n",
        "print(\"Feature-Matrix (Test):\", X_test.shape)\n",
        "print(\"Target (Test):\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "EQJl2pb2ynqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost-Modellaufbau**\n",
        "zur Vorhersage von numerischen Werten in dem Fall Verkaufszahlen"
      ],
      "metadata": {
        "id": "dYiIgMfs233X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost-Baseline"
      ],
      "metadata": {
        "id": "jCP24aU_v3g8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "n_estimators=250 = Anzahl der Bäume:\n",
        "Das Modell besteht aus 250 Entscheidungsbäumen. Mehr Bäume = stärkeres Modell (aber langsamer).\n",
        "\n",
        "learning_rate=0.1 = Lernrate:\n",
        "Wie stark jeder neue Baum die Gesamtvorhersage korrigiert. Kleinere Werte lernen langsamer, aber stabiler.\n",
        "\n",
        "\n",
        "max_depth=7 = Maximale Tiefe der Bäume:\n",
        "Wie viele „Fragen“ ein Baum stellen darf. Tiefer = komplexer, aber riskanter (Overfitting).\n",
        "\n",
        "random_state=42 = Zufallsstartwert:\n",
        "Damit die Ergebnisse reproduzierbar bleiben.\n",
        "\n",
        "n_jobs=-1 = Anzahl der Prozessorkerne:\n",
        "-1 bedeutet: benutze alle verfügbaren Kerne, um schneller zu rechnen."
      ],
      "metadata": {
        "id": "6hKuWEmNT42R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "model = XGBRegressor(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=7,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"✅ Modell trainiert! Anzahl Vorhersagen:\", len(y_pred))\n"
      ],
      "metadata": {
        "id": "2FmyFIsZ27Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "daily_sales = df_train_filtered[['unit_sales', 'unit_sales_7d_avg', 'rolling_std_7']].resample('D').mean()\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.plot(daily_sales.index, daily_sales['unit_sales'], label='unit_sales', color='black',linewidth=1, alpha=0.7)\n",
        "plt.plot(daily_sales.index, daily_sales['unit_sales_7d_avg'], label='unit_sales_7d_avg', linewidth=2,  color='blue')\n",
        "plt.plot(daily_sales.index, daily_sales['rolling_std_7'], label='rolling_std_7', linewidth=2,  color='magenta')\n",
        "plt.title('Original Sales, 7-day Rolling Mean, and 7-day Rolling Std Dev')\n",
        "plt.xlabel('Datum')\n",
        "plt.ylabel('Verkäufe')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XAAjZHD-7ulp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "y_pred = pd.Series(y_pred, index=y_test.index)\n",
        "\n",
        "print(\"Länge y_test:\", len(y_test))\n",
        "print(\"Länge y_pred:\", len(y_pred))\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolut Error : {mae:.4f} units: Das Modell sagt sehr nah an den echten Werten voraus.\")\n",
        "print(f\"Mean Squared Error : {mse:.4f} units: Es gibt einzelne größere Fehler, aber insgesamt ist das Modell stabil.\")\n"
      ],
      "metadata": {
        "id": "qUr0tqixAYIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bewertung meiner XGBoost-Baseline"
      ],
      "metadata": {
        "id": "dIuhPJrQujSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der gezeigte Code definiert eine Funktion zur Bewertung der Modellleistung anhand typischer Prognosemetriken.\n",
        "Mit der Funktion forecast_metrics(y_true, y_pred) werden wichtige Kennzahlen berechnet, die zeigen, wie gut das XGBoost-Modell die Verkaufszahlen vorhersagt.\n",
        "\n",
        "Dazu gehören:\n",
        "\n",
        "- MAE (Mean Absolute Error): durchschnittlicher absoluter Fehler – misst die Genauigkeit.\n",
        "\n",
        "- Bias: zeigt, ob das Modell systematisch über- oder unterschätzt.\n",
        "\n",
        "- MAD / rMAD: mittlere absolute Abweichung und deren relatives Verhältnis.\n",
        "\n",
        "- MAPE (Mean Absolute Percentage Error): prozentuale Abweichung der Vorhersagen vom tatsächlichen Wert.\n",
        "\n",
        "- RMSE (Root Mean Squared Error): gibt stärkere Gewichtung auf größere Fehler.\n",
        "\n",
        "Diese Metriken sind entscheidend, um die Qualität eines Prognosemodells objektiv zu bewerten.\n",
        "Sie ermöglichen es, Stärken und Schwächen des Modells zu erkennen und bilden die Grundlage für die spätere Optimierung des XGBoost-Modells.\n",
        "\n",
        "Der Code liefert den ersten, quantitativen Beweis, wie zuverlässig deine Baseline-Vorhersage wirklich ist – ein essenzieller Schritt im gesamten Machine-Learning-Projekt."
      ],
      "metadata": {
        "id": "QkOK91hXQJrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def forecast_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute a common set of forecast-error statistics.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : 1-D array-like\n",
        "        Actual (ground-truth) values.\n",
        "    y_pred : 1-D array-like\n",
        "        Forecasted values.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Keys: 'MAE', 'Bias', 'MAD', 'rMAD', 'MAPE', 'RMSE'\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=float).flatten()\n",
        "    y_pred = np.asarray(y_pred, dtype=float).flatten()\n",
        "\n",
        "    errors       = y_true - y_pred\n",
        "    abs_errors   = np.abs(errors)\n",
        "    pct_errors   = abs_errors / np.where(y_true == 0, np.nan, y_true)\n",
        "\n",
        "    mae   = abs_errors.mean()\n",
        "    bias  = errors.mean()\n",
        "    rmse  = np.sqrt((errors ** 2).mean())\n",
        "\n",
        "    mad   = np.abs(y_true - y_true.mean()).mean()\n",
        "\n",
        "    rmad  = mae / mad if mad else np.nan\n",
        "\n",
        "    mape  = np.nanmean(pct_errors) * 100\n",
        "\n",
        "    return {\n",
        "        \"MAE\" : mae,\n",
        "        \"Bias\": bias,\n",
        "        \"MAD\" : mad,\n",
        "        \"rMAD\": rmad,\n",
        "        \"MAPE\": mape,\n",
        "        \"RMSE\": rmse\n",
        "    }"
      ],
      "metadata": {
        "id": "Jewjtl24uiwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = forecast_metrics(y_test, y_pred)\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:,.2f}\")"
      ],
      "metadata": {
        "id": "Wro_gzONuppd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimierung von XGBoost-Baseline: Hyperparamtertuning\n",
        "\n"
      ],
      "metadata": {
        "id": "rXNJ0YERuxmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Abschnitt wird die Leistungsfähigkeit des XGBoost-Modells durch gezieltes Hyperparametertuning verbessert.\n",
        "Anstatt feste Parameter zu verwenden, wird hier mit einer RandomizedSearchCV eine Vielzahl möglicher Parameterkombinationen getestet, um jene Konfiguration zu finden, die den niedrigsten Fehler (RMSE) erzielt.\n",
        "\n",
        "**Vorgehen:**\n",
        "\n",
        "Parameterraum definieren:\n",
        "Es werden verschiedene Wertebereiche für wichtige Parameter festgelegt, z. B.\n",
        "\n",
        "- learning_rate: Lernrate des Modells\n",
        "\n",
        "- max_depth: maximale Baumtiefe\n",
        "\n",
        "- subsample & colsample_bytree: Anteil der Daten und Features pro Baum\n",
        "\n",
        "- n_estimators: Anzahl der Entscheidungsbäume\n",
        "\n",
        "Zeitreihen-Cross-Validation (TimeSeriesSplit):\n",
        "Da es sich um Zeitreihendaten handelt, wird eine spezielle Validierung verwendet, die den zeitlichen Verlauf respektiert – das verhindert Datenleckagen.\n",
        "\n",
        "RandomizedSearchCV:\n",
        "Diese Methode wählt zufällig Kombinationen aus dem Parameterraster aus und testet sie, um die besten Parameter effizient zu finden (schneller als GridSearchCV).\n",
        "\n",
        "Trainieren & Bewerten:\n",
        "Mit den optimalen Parametern wird das finale Modell neu trainiert und anhand der zuvor definierten Metriken (MAE, RMSE, MAPE usw.) bewertet.\n",
        "\n",
        "Visualisierung:\n",
        "Die grafische Darstellung zeigt die tatsächlichen Verkaufszahlen im Vergleich zu den vorhergesagten Werten — ein wichtiger Schritt zur visuellen Bewertung der Modellqualität."
      ],
      "metadata": {
        "id": "UuQIXtTlRuMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "\n",
        "xgb = XGBRegressor(objective='reg:squarederror')"
      ],
      "metadata": {
        "id": "ZehQE84DuxJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition von Parameterraster\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'n_estimators': [100, 200, 300, 500]\n",
        "}\n",
        "\n",
        "tscv = TimeSeriesSplit()\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=xgb,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t param_distributions=param_grid,\n",
        "                                   cv=tscv,\n",
        "                                   n_iter=10,\n",
        "                                   scoring='neg_mean_squared_error')\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters for XGBoost:\", best_params)\n",
        "\n",
        "final_model = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=best_params[\"n_estimators\"],\n",
        "    max_depth=best_params[\"max_depth\"],\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    subsample=best_params[\"subsample\"],\n",
        "    colsample_bytree=best_params[\"colsample_bytree\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "metrics = forecast_metrics(y_test, y_pred)\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:,.2f}\")\n",
        "\n",
        "# Visualize actual vs. predicted\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(y_test, label='Actual')\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.legend()\n",
        "plt.title('XGBoost Forecast vs. Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0rjMRD0IvCaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLflow-Setup für XGBoost"
      ],
      "metadata": {
        "id": "V4i40aSgw-wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Abschnitt wird MLflow genutzt, um das Training und die Bewertung des XGBoost-Modells automatisch zu protokollieren.\n",
        "Alle wichtigen Informationen – wie Parameter, Metriken, Modelle und Diagramme – werden gespeichert, damit die Experimente vergleichbar und reproduzierbar bleiben.\n",
        "\n",
        "Der Code:\n",
        "\n",
        "- erstellt ein MLflow-Experiment (XGBoost_Basislinie),\n",
        "\n",
        "- trainiert das Modell und berechnet Prognosemetriken,\n",
        "\n",
        "- speichert alle Ergebnisse und das Modell direkt in MLflow.\n",
        "\n",
        "So wird sichergestellt, dass jede Modellversion dokumentiert ist und später leicht verglichen oder erneut geladen werden kann.\n",
        "Ein zentraler Schritt für Nachvollziehbarkeit und sauberes Experiment-Tracking."
      ],
      "metadata": {
        "id": "DeSStvoeShIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FW8JRoQN0gb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLflow-Setup für XGBoost-Basislinie\n",
        "\n",
        "import mlflow\n",
        "import mlflow.xgboost\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# MLflow Setup\n",
        "mlflow.set_experiment(\"XGBoost_Basislinie\")  # Name des Experiments\n",
        "\n",
        "# Rahmenparameter definiert\n",
        "baseline_params = {\n",
        "    \"n_estimators\": 250,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"max_depth\": 7,\n",
        "    \"random_state\": 42,\n",
        "    \"n_jobs\": -1,\n",
        "    \"objective\": \"reg:squarederror\"\n",
        "}\n",
        "\n",
        "# Start meines 1. Laufs\n",
        "with mlflow.start_run(run_name=\"Basis-XGB\"):\n",
        "\n",
        "    # Modellaufbau & Training\n",
        "    model = XGBRegressor(**baseline_params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Vorhersagen\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Metriken berechnen\n",
        "    metrics = forecast_metrics(y_test, y_pred)\n",
        "\n",
        "    # Parameter & Metriken in MLflow speichern\n",
        "    mlflow.log_params(baseline_params)\n",
        "    mlflow.log_metrics({k: float(v) for k, v in metrics.items()})\n",
        "\n",
        "    # Prognose-Diagramm erstellen\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(y_test, label=\"Wahre Werte\", color=\"blue\")\n",
        "    plt.plot(y_pred, label=\"Vorhersage\", color=\"orange\")\n",
        "    plt.title(\"XGBoost-Basislinie: Wahre Werte vs. Vorhersage\")\n",
        "    plt.xlabel(\"Zeitindex\")\n",
        "    plt.ylabel(\"Verkaufswert\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Diagramm speichern und als Artefakt hochladen\n",
        "    plt.savefig(\"forecast_plot.png\")\n",
        "    mlflow.log_artifact(\"forecast_plot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Modell selbst speichern\n",
        "    mlflow.xgboost.log_model(model, artifact_path=\"xgb_model_baseline\")\n",
        "\n",
        "    # Tags setzen\n",
        "    mlflow.set_tag(\"stage\", \"baseline\")\n",
        "    mlflow.set_tag(\"model_type\", \"XGBoost\")\n",
        "\n",
        "    print(\"✅ MLflow-Basislauf abgeschlossen!\")\n",
        "    print(\"🔍 Ergebnisse im MLflow-UI anzeigen mit:  mlflow ui\")"
      ],
      "metadata": {
        "id": "AHPi4WXbw-aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "# Dein Experiment-Name aus dem Code\n",
        "exp_name = \"XGBoost_Basislinie\"\n",
        "\n",
        "# Experiment-ID holen\n",
        "exp = mlflow.get_experiment_by_name(exp_name)\n",
        "\n",
        "# Alle Runs als DataFrame ziehen\n",
        "runs_df = mlflow.search_runs(\n",
        "    experiment_ids=[exp.experiment_id],\n",
        "    output_format=\"pandas\"\n",
        ")\n",
        "\n",
        "# Nur die wichtigsten Spalten zeigen\n",
        "cols = [\n",
        "    \"run_id\", \"tags.stage\", \"params.n_estimators\", \"params.learning_rate\",\n",
        "    \"params.max_depth\", \"metrics.MAE\", \"metrics.RMSE\", \"metrics.MAPE\"\n",
        "]\n",
        "display(runs_df[cols].sort_values(\"metrics.RMSE\"))\n"
      ],
      "metadata": {
        "id": "OH_A4gv23rw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Lauf – MLflow für optimiertes XGBoost-Modell"
      ],
      "metadata": {
        "id": "zNij81QhxOm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Zweiter MLflow-Lauf: Optimiertes Modell\n",
        "with mlflow.start_run(run_name=\"Optimiertes-XGB\"):\n",
        "\n",
        "    # Trainiere Modell mit den besten Parametern aus RandomizedSearchCV\n",
        "    optimized_model = XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        n_estimators=best_params[\"n_estimators\"],\n",
        "        max_depth=best_params[\"max_depth\"],\n",
        "        learning_rate=best_params[\"learning_rate\"],\n",
        "        subsample=best_params[\"subsample\"],\n",
        "        colsample_bytree=best_params[\"colsample_bytree\"],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    optimized_model.fit(X_train, y_train)\n",
        "    y_pred_opt = optimized_model.predict(X_test)\n",
        "\n",
        "    # Berechne Metriken\n",
        "    metrics_opt = forecast_metrics(y_test, y_pred_opt)\n",
        "\n",
        "    # Logge Parameter und Metriken in MLflow\n",
        "    mlflow.log_params(best_params)\n",
        "    mlflow.log_metrics(metrics_opt)\n",
        "\n",
        "    # Erstelle Vergleichsdiagramm (tatsächliche vs. vorhergesagte Werte)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(y_test.values[:200], label=\"Wahre Werte\", color=\"blue\")\n",
        "    plt.plot(y_pred_opt[:200], label=\"Optimierte Vorhersage\", color=\"green\")\n",
        "    plt.title(\"Optimiertes XGBoost-Modell: Wahr vs. Vorhergesagt\")\n",
        "    plt.xlabel(\"Zeitindex\")\n",
        "    plt.ylabel(\"Verkaufswert\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"optimized_forecast_plot.png\")\n",
        "\n",
        "    # Logge Diagramm und Modell\n",
        "    mlflow.log_artifact(\"optimized_forecast_plot.png\")\n",
        "    mlflow.xgboost.log_model(optimized_model, artifact_path=\"xgb_model_optimized\")\n",
        "\n",
        "    # Setze Tags (optional, für Übersicht)\n",
        "    mlflow.set_tag(\"stage\", \"optimized\")\n",
        "    mlflow.set_tag(\"model_type\", \"XGBoost\")\n",
        "\n",
        "    print(\"✅ Zweiter MLflow-Lauf abgeschlossen! (Optimiertes Modell)\")\n"
      ],
      "metadata": {
        "id": "_9UX_g0VxJd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊Vergleich Baseline vs. Optimiertes Modell: XGBoost"
      ],
      "metadata": {
        "id": "z28jymq04mPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Schritt werden die Ergebnisse des Basismodells und des optimierten XGBoost-Modells direkt miteinander verglichen.\n",
        "Dazu werden die gespeicherten MLflow-Runs geladen und die wichtigsten Metriken (z. B. RMSE, MAE, MAPE) ausgewertet.\n",
        "\n",
        "Die Balkengrafik zeigt die Unterschiede in der Modellleistung auf einen Blick – insbesondere beim RMSE-Wert, der die Prognosegenauigkeit misst.\n",
        "So lässt sich leicht erkennen, ob das Tuning tatsächlich zu einer Verbesserung der Vorhersagequalität geführt hat.\n",
        "\n",
        "Ein wichtiger Schritt, um den Erfolg des Modelltrainings objektiv zu bewerten."
      ],
      "metadata": {
        "id": "6Q9TrvVMTdc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Experiment-Name aus deinen Runs\n",
        "exp_name = \"XGBoost_Basislinie\"\n",
        "\n",
        "# Experiment-ID holen\n",
        "exp = mlflow.get_experiment_by_name(exp_name)\n",
        "\n",
        "# Alle Runs laden\n",
        "runs_df = mlflow.search_runs(\n",
        "    experiment_ids=[exp.experiment_id],\n",
        "    output_format=\"pandas\"\n",
        ")\n",
        "\n",
        "# Nur wichtige Spalten anzeigen\n",
        "cols = [\n",
        "    \"tags.stage\",\n",
        "    \"params.n_estimators\",\n",
        "    \"params.learning_rate\",\n",
        "    \"params.max_depth\",\n",
        "    \"metrics.MAE\",\n",
        "    \"metrics.RMSE\",\n",
        "    \"metrics.MAPE\"\n",
        "]\n",
        "\n",
        "comparison_df = runs_df[cols].sort_values(\"metrics.RMSE\").reset_index(drop=True)\n",
        "display(comparison_df)\n"
      ],
      "metadata": {
        "id": "v6S8bn_w4qJZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visuelle Gegenüberstellung (Barplot der Metriken)"
      ],
      "metadata": {
        "id": "jgI5zMMJ4wa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(comparison_df[\"tags.stage\"], comparison_df[\"metrics.RMSE\"], color=[\"orange\", \"green\"])\n",
        "plt.title(\"Vergleich: RMSE Baseline vs. Optimiert\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.xlabel(\"Modell\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jHnlUvtf4sOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Schritt wird aus allen gespeicherten MLflow-Runs automatisch das Modell mit dem besten RMSE-Wert ermittelt – also jenes, das die genauesten Vorhersagen liefert.\n",
        "\n",
        "Der Code durchsucht die gespeicherten Ergebnisse, gibt die beste Run-ID aus und lädt das entsprechende Modell direkt aus MLflow.\n",
        "Dadurch kannst du das leistungsstärkste Modell jederzeit wiederverwenden, ohne es neu trainieren zu müssen.\n",
        "\n",
        "Ein wichtiger Schritt für Effizienz und Nachvollziehbarkeit im Modellmanagement."
      ],
      "metadata": {
        "id": "8n7QS845TpcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.xgboost\n",
        "import pandas as pd\n",
        "\n",
        "# Name deines MLflow-Experiments\n",
        "exp_name = \"XGBoost_Basislinie\"\n",
        "\n",
        "# Experiment holen\n",
        "exp = mlflow.get_experiment_by_name(exp_name)\n",
        "\n",
        "# Alle Runs abrufen\n",
        "runs_df = mlflow.search_runs(\n",
        "    experiment_ids=[exp.experiment_id],\n",
        "    output_format=\"pandas\"\n",
        ")\n",
        "\n",
        "# Besten Run anhand des niedrigsten RMSE finden\n",
        "best_run = runs_df.loc[runs_df[\"metrics.RMSE\"].idxmin()]\n",
        "best_run_id = best_run[\"run_id\"]\n",
        "\n",
        "print(\"🏆 Bestes Modell gefunden!\")\n",
        "print(f\"Stage: {best_run['tags.stage']}\")\n",
        "print(f\"RMSE: {best_run['metrics.RMSE']:.4f}\")\n",
        "print(f\"Run-ID: {best_run_id}\")\n"
      ],
      "metadata": {
        "id": "XL8mXOaX47cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modell aus MLflow laden\n",
        "model_uri = f\"runs:/{best_run_id}/xgb_model_optimized\"  # oder xgb_model_baseline, falls du das willst\n",
        "best_model = mlflow.xgboost.load_model(model_uri)\n",
        "\n",
        "print(\"✅ Modell erfolgreich geladen!\")\n"
      ],
      "metadata": {
        "id": "CpeG6ocC48vL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
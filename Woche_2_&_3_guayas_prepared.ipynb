{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ui6VpGcAyjss",
        "jCP24aU_v3g8",
        "dIuhPJrQujSZ",
        "rXNJ0YERuxmd",
        "V4i40aSgw-wD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Ziel: Entwicklung eines ML-Modells zur Nachfrageprognose**"
      ],
      "metadata": {
        "id": "fnfBZzsc1rqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "\n",
        "def make_drive_url(file_id):\n",
        "    return f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Hilfsfunktion zum Laden einer CSV-Datei Ã¼ber eine direkte URL\n",
        "def load_csv_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return pd.read_csv(io.StringIO(response.text))\n",
        "\n",
        "    # Verzeichnis der Datei-IDs zur besseren Ãœbersichtlichkeit\n",
        "file_ids = {\n",
        "    \"holiday_events\": \"1RMjSuqHXHTwAw_PGD5XVjhA3agaAGHDH\",\n",
        "    \"items\": \"1ogMRixVhNY6XOJtIRtkRllyOyzw1nqya\",\n",
        "    \"oil\": \"1Q59vk2v4WQ-Rpc9t2nqHcsZM3QWGFje_\",\n",
        "    \"stores\": \"1Ei0MUXmNhmOcmrlPad8oklnFEDM95cDi\",\n",
        "    \"train\": \"1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv\",\n",
        "    \"transactions\": \"1PW5LnAEAiL43fI5CRDn_h6pgDG5rtBW_\"\n",
        "}\n",
        "\n",
        "df_holiday_events = load_csv_from_url(make_drive_url(file_ids[\"holiday_events\"]))\n",
        "df_items          = load_csv_from_url(make_drive_url(file_ids[\"items\"]))\n",
        "df_oil            = load_csv_from_url(make_drive_url(file_ids[\"oil\"]))\n",
        "df_stores         = load_csv_from_url(make_drive_url(file_ids[\"stores\"]))\n",
        "df_transactions   = load_csv_from_url(make_drive_url(file_ids[\"transactions\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZlahpvAsd7Gh",
        "outputId": "4817a059-ad0d-4602-ecc8-090c523b3251"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ÃœberprÃ¼fung der Region - Guayas**\n",
        "\n",
        "Der Datensatz wurde mit den Filialinformationen verknÃ¼pft, um sicherzustellen, dass alle EintrÃ¤ge aus der Provinz Guayas stammen."
      ],
      "metadata": {
        "id": "W-FHijVfuWGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUGl6eXhCMs_",
        "outputId": "b9b4a77e-3963-4b99-90d7-f9426bf4b355"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/MyDrive/Data Science Sinem/Time Series/df_train_filtered_top3_final.pkl'\n",
        "\n",
        "df_train = pd.read_pickle(path)\n",
        "\n",
        "print(f\"âœ… Datei geladen: {len(df_train):,} Zeilen und {len(df_train.columns)} Spalten\")\n",
        "df_train.head()\n"
      ],
      "metadata": {
        "id": "rkV7iw16tnjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_stores.columns)\n"
      ],
      "metadata": {
        "id": "Z_TQs3HItxLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VerknÃ¼pfen der Verkaufsdaten mit den Filialinformationen\n",
        "df_merged = df_train.merge(df_stores[['store_nbr', 'state']], on='store_nbr', how='left')\n",
        "\n",
        "print(f\"âœ… Nach Merge: {len(df_merged):,} Zeilen, {len(df_merged.columns)} Spalten\")\n",
        "df_merged.head()\n"
      ],
      "metadata": {
        "id": "dSLR3Wf6tzzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_merged['state'].value_counts())\n"
      ],
      "metadata": {
        "id": "PouysMvDt4A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filterung auf die Top-3-Familien**\n",
        "\n",
        "Um die Analyse gezielt auf die wichtigsten Produktgruppen zu konzentrieren, wird der Datensatz auf die drei hÃ¤ufigsten Familien â€GROCERY Iâ€œ, â€BEVERAGESâ€œ und â€CLEANINGâ€œ eingeschrÃ¤nkt."
      ],
      "metadata": {
        "id": "_I3VJeRluzEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_items"
      ],
      "metadata": {
        "id": "1Gjr36a0vZ6j",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definieren der Top-3-Familien\n",
        "top_families = ['GROCERY I', 'BEVERAGES', 'CLEANING']\n",
        "\n",
        "item_ids = df_items[df_items['family'].isin(top_families)]['item_nbr'].unique()\n",
        "\n",
        "# Trainingsdaten filtern\n",
        "df_train_filtered = df_train[df_train['item_nbr'].isin(item_ids)]\n",
        "\n",
        "# Kontrolle\n",
        "print(f\"âœ… Gefilterte Daten: {len(df_train_filtered):,} Zeilen\")\n",
        "print(df_items['family'].value_counts())\n"
      ],
      "metadata": {
        "id": "rdFpUvFgu4Ke",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_filtered"
      ],
      "metadata": {
        "id": "Hnih6ud9vVmA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Der Datensatz wird auf das erste Quartal 2014 **(1. Januar bis 31. MÃ¤rz)** begrenzt, um einen Ã¼berschaubaren Zeitraum fÃ¼r das Modelltraining zu verwenden."
      ],
      "metadata": {
        "id": "eVqHf6mTwrnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeitraum definieren\n",
        "start_date = '2014-01-01'\n",
        "end_date = '2014-03-31'\n",
        "\n",
        "df_train_filtered = df_train_filtered[\n",
        "    (df_train_filtered['date'] >= start_date) &\n",
        "    (df_train_filtered['date'] <= end_date)\n",
        "]"
      ],
      "metadata": {
        "id": "-AxwAoXgweW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_filtered"
      ],
      "metadata": {
        "id": "EUrxvG3mwjQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Im Rahmen des Feature Engineerings werden zeitbasierte Merkmale (Jahr, Monat, Wochentag), Lag-Features und gleitende Durchschnitte erstellt, um Trends und saisonale Effekte fÃ¼r XGBoost sichtbar zu machen."
      ],
      "metadata": {
        "id": "Lcrq7Vd7xow2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lag-Features (VerzÃ¶gerungen) erstellen â€” vergangene Verkaufswerte\n",
        "df_train_filtered = df_train_filtered.sort_values(['store_nbr', 'item_nbr', 'date'])\n",
        "\n",
        "df_train_filtered['lag_1'] = df_train_filtered['unit_sales'].shift(1)\n",
        "df_train_filtered['lag_7'] = df_train_filtered['unit_sales'].shift(7)\n",
        "df_train_filtered['lag_30'] = df_train_filtered['unit_sales'].shift(30)\n",
        "\n",
        "\n",
        "df_train_filtered['rolling_std_7'] = df_train_filtered['unit_sales'].shift(1).rolling(window=7).std()\n",
        "\n",
        "# Fehlende Werte nach Shifts auffÃ¼llen (optional)\n",
        "df_train_filtered = df_train_filtered.fillna(0)\n",
        "\n",
        "df_train_filtered = df_train_filtered.set_index('date')\n",
        "\n",
        "# Kontrolle\n",
        "print(\"âœ… Neue Features hinzugefÃ¼gt:\")\n",
        "print(df_train_filtered.columns)\n",
        "df_train_filtered"
      ],
      "metadata": {
        "id": "ym7va-B0xWve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = df_train_filtered.merge(df_stores, on='store_nbr', how='left')\n",
        "\n",
        "df_merged = df_merged.merge(df_items, on='item_nbr', how='left')\n",
        "\n",
        "print(\"âœ… Daten erfolgreich zusammengefÃ¼hrt!\")\n",
        "print(f\"â¡ï¸ Zeilen: {len(df_merged):,}\")\n",
        "print(f\"â¡ï¸ Spalten: {len(df_merged.columns)}\")\n",
        "print(\"\\nğŸ§  Neue Spaltenbeispiele:\")\n",
        "print(df_merged.columns.tolist()[:15])  # Zeigt die ersten Spaltennamen\n",
        "print(\"\\nğŸ“Š Stichprobe:\")\n",
        "display(df_merged.head(3))\n"
      ],
      "metadata": {
        "id": "diXk6-P5yNYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aufteilung Training/Test**"
      ],
      "metadata": {
        "id": "Ui6VpGcAyjss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Datum sicherstellen\n",
        "df_train_filtered.index = pd.to_datetime(df_train_filtered.index)\n",
        "df_train_filtered = df_train_filtered.sort_index()\n",
        "\n",
        "# ZeitrÃ¤ume festlegen\n",
        "train_start = '2014-01-01'\n",
        "train_end   = '2014-02-28'\n",
        "test_start  = '2014-03-01'\n",
        "test_end    = '2014-03-31'\n",
        "\n",
        "# Masken auf Basis des Index erstellen\n",
        "train_mask = (df_train_filtered.index >= train_start) & (df_train_filtered.index <= train_end)\n",
        "test_mask  = (df_train_filtered.index >= test_start)  & (df_train_filtered.index <= test_end)\n",
        "\n",
        "# Daten filtern\n",
        "df_train = df_train_filtered.loc[train_mask]\n",
        "df_test  = df_train_filtered.loc[test_mask]\n",
        "\n",
        "# Kontrolle\n",
        "print(\"âœ… Trainingsdaten:\", len(df_train),\n",
        "      \"Zeilen von\", df_train.index.min(), \"bis\", df_train.index.max())\n",
        "\n",
        "print(\"âœ… Testdaten:\", len(df_test),\n",
        "      \"Zeilen von\", df_test.index.min(), \"bis\", df_test.index.max())\n"
      ],
      "metadata": {
        "id": "toV1Vtrv2fDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'unit_sales'\n",
        "\n",
        "feature_cols = [\n",
        "    'store_nbr',\n",
        "    'item_nbr',\n",
        "    'onpromotion',\n",
        "    'z_score',\n",
        "    'year',\n",
        "    'month',\n",
        "    'day_of_week',\n",
        "    'unit_sales_7d_avg'\n",
        "]\n",
        "\n",
        "# Trainingsdaten trennen\n",
        "X_train = df_train[feature_cols]\n",
        "y_train = df_train[target_col]\n",
        "\n",
        "# ğŸ”¹ Testdaten trennen\n",
        "X_test = df_test[feature_cols]\n",
        "y_test = df_test[target_col]\n",
        "\n",
        "# Kontrolle\n",
        "print(\"Feature-Matrix (Train):\", X_train.shape)\n",
        "print(\"Target (Train):\", y_train.shape)\n",
        "print(\"Feature-Matrix (Test):\", X_test.shape)\n",
        "print(\"Target (Test):\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "EQJl2pb2ynqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost-Modellaufbau**\n",
        "zur Vorhersage von numerischen Werten in dem Fall Verkaufszahlen"
      ],
      "metadata": {
        "id": "dYiIgMfs233X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost-Baseline"
      ],
      "metadata": {
        "id": "jCP24aU_v3g8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "n_estimators=250 = Anzahl der BÃ¤ume:\n",
        "Das Modell besteht aus 250 EntscheidungsbÃ¤umen. Mehr BÃ¤ume = stÃ¤rkeres Modell (aber langsamer).\n",
        "\n",
        "learning_rate=0.1 = Lernrate:\n",
        "Wie stark jeder neue Baum die Gesamtvorhersage korrigiert. Kleinere Werte lernen langsamer, aber stabiler.\n",
        "\n",
        "\n",
        "max_depth=7 = Maximale Tiefe der BÃ¤ume:\n",
        "Wie viele â€Fragenâ€œ ein Baum stellen darf. Tiefer = komplexer, aber riskanter (Overfitting).\n",
        "\n",
        "random_state=42 = Zufallsstartwert:\n",
        "Damit die Ergebnisse reproduzierbar bleiben.\n",
        "\n",
        "n_jobs=-1 = Anzahl der Prozessorkerne:\n",
        "-1 bedeutet: benutze alle verfÃ¼gbaren Kerne, um schneller zu rechnen."
      ],
      "metadata": {
        "id": "6hKuWEmNT42R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "model = XGBRegressor(\n",
        "    n_estimators=250,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=7,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"âœ… Modell trainiert! Anzahl Vorhersagen:\", len(y_pred))\n"
      ],
      "metadata": {
        "id": "2FmyFIsZ27Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "daily_sales = df_train_filtered[['unit_sales', 'unit_sales_7d_avg', 'rolling_std_7']].resample('D').mean()\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.plot(daily_sales.index, daily_sales['unit_sales'], label='unit_sales', color='black',linewidth=1, alpha=0.7)\n",
        "plt.plot(daily_sales.index, daily_sales['unit_sales_7d_avg'], label='unit_sales_7d_avg', linewidth=2,  color='blue')\n",
        "plt.plot(daily_sales.index, daily_sales['rolling_std_7'], label='rolling_std_7', linewidth=2,  color='magenta')\n",
        "plt.title('Original Sales, 7-day Rolling Mean, and 7-day Rolling Std Dev')\n",
        "plt.xlabel('Datum')\n",
        "plt.ylabel('VerkÃ¤ufe')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XAAjZHD-7ulp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "y_pred = pd.Series(y_pred, index=y_test.index)\n",
        "\n",
        "print(\"LÃ¤nge y_test:\", len(y_test))\n",
        "print(\"LÃ¤nge y_pred:\", len(y_pred))\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolut Error : {mae:.4f} units: Das Modell sagt sehr nah an den echten Werten voraus.\")\n",
        "print(f\"Mean Squared Error : {mse:.4f} units: Es gibt einzelne grÃ¶ÃŸere Fehler, aber insgesamt ist das Modell stabil.\")\n"
      ],
      "metadata": {
        "id": "qUr0tqixAYIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bewertung meiner XGBoost-Baseline"
      ],
      "metadata": {
        "id": "dIuhPJrQujSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der gezeigte Code definiert eine Funktion zur Bewertung der Modellleistung anhand typischer Prognosemetriken.\n",
        "Mit der Funktion forecast_metrics(y_true, y_pred) werden wichtige Kennzahlen berechnet, die zeigen, wie gut das XGBoost-Modell die Verkaufszahlen vorhersagt.\n",
        "\n",
        "Dazu gehÃ¶ren:\n",
        "\n",
        "- MAE (Mean Absolute Error): durchschnittlicher absoluter Fehler â€“ misst die Genauigkeit.\n",
        "\n",
        "- Bias: zeigt, ob das Modell systematisch Ã¼ber- oder unterschÃ¤tzt.\n",
        "\n",
        "- MAD / rMAD: mittlere absolute Abweichung und deren relatives VerhÃ¤ltnis.\n",
        "\n",
        "- MAPE (Mean Absolute Percentage Error): prozentuale Abweichung der Vorhersagen vom tatsÃ¤chlichen Wert.\n",
        "\n",
        "- RMSE (Root Mean Squared Error): gibt stÃ¤rkere Gewichtung auf grÃ¶ÃŸere Fehler.\n",
        "\n",
        "Diese Metriken sind entscheidend, um die QualitÃ¤t eines Prognosemodells objektiv zu bewerten.\n",
        "Sie ermÃ¶glichen es, StÃ¤rken und SchwÃ¤chen des Modells zu erkennen und bilden die Grundlage fÃ¼r die spÃ¤tere Optimierung des XGBoost-Modells.\n",
        "\n",
        "Der Code liefert den ersten, quantitativen Beweis, wie zuverlÃ¤ssig deine Baseline-Vorhersage wirklich ist â€“ ein essenzieller Schritt im gesamten Machine-Learning-Projekt."
      ],
      "metadata": {
        "id": "QkOK91hXQJrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def forecast_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute a common set of forecast-error statistics.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : 1-D array-like\n",
        "        Actual (ground-truth) values.\n",
        "    y_pred : 1-D array-like\n",
        "        Forecasted values.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Keys: 'MAE', 'Bias', 'MAD', 'rMAD', 'MAPE', 'RMSE'\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=float).flatten()\n",
        "    y_pred = np.asarray(y_pred, dtype=float).flatten()\n",
        "\n",
        "    errors       = y_true - y_pred\n",
        "    abs_errors   = np.abs(errors)\n",
        "    pct_errors   = abs_errors / np.where(y_true == 0, np.nan, y_true)\n",
        "\n",
        "    mae   = abs_errors.mean()\n",
        "    bias  = errors.mean()\n",
        "    rmse  = np.sqrt((errors ** 2).mean())\n",
        "\n",
        "    mad   = np.abs(y_true - y_true.mean()).mean()\n",
        "\n",
        "    rmad  = mae / mad if mad else np.nan\n",
        "\n",
        "    mape  = np.nanmean(pct_errors) * 100\n",
        "\n",
        "    return {\n",
        "        \"MAE\" : mae,\n",
        "        \"Bias\": bias,\n",
        "        \"MAD\" : mad,\n",
        "        \"rMAD\": rmad,\n",
        "        \"MAPE\": mape,\n",
        "        \"RMSE\": rmse\n",
        "    }"
      ],
      "metadata": {
        "id": "Jewjtl24uiwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = forecast_metrics(y_test, y_pred)\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:,.2f}\")"
      ],
      "metadata": {
        "id": "Wro_gzONuppd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimierung von XGBoost-Baseline: Hyperparamtertuning\n",
        "\n"
      ],
      "metadata": {
        "id": "rXNJ0YERuxmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Abschnitt wird die LeistungsfÃ¤higkeit des XGBoost-Modells durch gezieltes Hyperparametertuning verbessert.\n",
        "Anstatt feste Parameter zu verwenden, wird hier mit einer RandomizedSearchCV eine Vielzahl mÃ¶glicher Parameterkombinationen getestet, um jene Konfiguration zu finden, die den niedrigsten Fehler (RMSE) erzielt.\n",
        "\n",
        "**Vorgehen:**\n",
        "\n",
        "Parameterraum definieren:\n",
        "Es werden verschiedene Wertebereiche fÃ¼r wichtige Parameter festgelegt, z. B.\n",
        "\n",
        "- learning_rate: Lernrate des Modells\n",
        "\n",
        "- max_depth: maximale Baumtiefe\n",
        "\n",
        "- subsample & colsample_bytree: Anteil der Daten und Features pro Baum\n",
        "\n",
        "- n_estimators: Anzahl der EntscheidungsbÃ¤ume\n",
        "\n",
        "Zeitreihen-Cross-Validation (TimeSeriesSplit):\n",
        "Da es sich um Zeitreihendaten handelt, wird eine spezielle Validierung verwendet, die den zeitlichen Verlauf respektiert â€“ das verhindert Datenleckagen.\n",
        "\n",
        "RandomizedSearchCV:\n",
        "Diese Methode wÃ¤hlt zufÃ¤llig Kombinationen aus dem Parameterraster aus und testet sie, um die besten Parameter effizient zu finden (schneller als GridSearchCV).\n",
        "\n",
        "Trainieren & Bewerten:\n",
        "Mit den optimalen Parametern wird das finale Modell neu trainiert und anhand der zuvor definierten Metriken (MAE, RMSE, MAPE usw.) bewertet.\n",
        "\n",
        "Visualisierung:\n",
        "Die grafische Darstellung zeigt die tatsÃ¤chlichen Verkaufszahlen im Vergleich zu den vorhergesagten Werten â€” ein wichtiger Schritt zur visuellen Bewertung der ModellqualitÃ¤t."
      ],
      "metadata": {
        "id": "UuQIXtTlRuMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "\n",
        "xgb = XGBRegressor(objective='reg:squarederror')"
      ],
      "metadata": {
        "id": "ZehQE84DuxJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition von Parameterraster\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    'n_estimators': [100, 200, 300, 500]\n",
        "}\n",
        "\n",
        "tscv = TimeSeriesSplit()\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=xgb,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t param_distributions=param_grid,\n",
        "                                   cv=tscv,\n",
        "                                   n_iter=10,\n",
        "                                   scoring='neg_mean_squared_error')\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters for XGBoost:\", best_params)\n",
        "\n",
        "final_model = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=best_params[\"n_estimators\"],\n",
        "    max_depth=best_params[\"max_depth\"],\n",
        "    learning_rate=best_params[\"learning_rate\"],\n",
        "    subsample=best_params[\"subsample\"],\n",
        "    colsample_bytree=best_params[\"colsample_bytree\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "metrics = forecast_metrics(y_test, y_pred)\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:,.2f}\")\n",
        "\n",
        "# Visualize actual vs. predicted\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(y_test, label='Actual')\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.legend()\n",
        "plt.title('XGBoost Forecast vs. Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0rjMRD0IvCaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLflow-Setup fÃ¼r XGBoost"
      ],
      "metadata": {
        "id": "V4i40aSgw-wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Abschnitt wird MLflow genutzt, um das Training und die Bewertung des XGBoost-Modells automatisch zu protokollieren.\n",
        "Alle wichtigen Informationen â€“ wie Parameter, Metriken, Modelle und Diagramme â€“ werden gespeichert, damit die Experimente vergleichbar und reproduzierbar bleiben.\n",
        "\n",
        "Der Code:\n",
        "\n",
        "- erstellt ein MLflow-Experiment (XGBoost_Basislinie),\n",
        "\n",
        "- trainiert das Modell und berechnet Prognosemetriken,\n",
        "\n",
        "- speichert alle Ergebnisse und das Modell direkt in MLflow.\n",
        "\n",
        "So wird sichergestellt, dass jede Modellversion dokumentiert ist und spÃ¤ter leicht verglichen oder erneut geladen werden kann.\n",
        "Ein zentraler Schritt fÃ¼r Nachvollziehbarkeit und sauberes Experiment-Tracking."
      ],
      "metadata": {
        "id": "DeSStvoeShIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FW8JRoQN0gb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLflow-Setup fÃ¼r XGBoost-Basislinie\n",
        "\n",
        "import mlflow\n",
        "import mlflow.xgboost\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# MLflow Setup\n",
        "mlflow.set_experiment(\"XGBoost_Basislinie\")  # Name des Experiments\n",
        "\n",
        "# Rahmenparameter definiert\n",
        "baseline_params = {\n",
        "    \"n_estimators\": 250,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"max_depth\": 7,\n",
        "    \"random_state\": 42,\n",
        "    \"n_jobs\": -1,\n",
        "    \"objective\": \"reg:squarederror\"\n",
        "}\n",
        "\n",
        "# Start meines 1. Laufs\n",
        "with mlflow.start_run(run_name=\"Basis-XGB\"):\n",
        "\n",
        "    # Modellaufbau & Training\n",
        "    model = XGBRegressor(**baseline_params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Vorhersagen\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Metriken berechnen\n",
        "    metrics = forecast_metrics(y_test, y_pred)\n",
        "\n",
        "    # Parameter & Metriken in MLflow speichern\n",
        "    mlflow.log_params(baseline_params)\n",
        "    mlflow.log_metrics({k: float(v) for k, v in metrics.items()})\n",
        "\n",
        "    # Prognose-Diagramm erstellen\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(y_test, label=\"Wahre Werte\", color=\"blue\")\n",
        "    plt.plot(y_pred, label=\"Vorhersage\", color=\"orange\")\n",
        "    plt.title(\"XGBoost-Basislinie: Wahre Werte vs. Vorhersage\")\n",
        "    plt.xlabel(\"Zeitindex\")\n",
        "    plt.ylabel(\"Verkaufswert\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Diagramm speichern und als Artefakt hochladen\n",
        "    plt.savefig(\"forecast_plot.png\")\n",
        "    mlflow.log_artifact(\"forecast_plot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Modell selbst speichern\n",
        "    mlflow.xgboost.log_model(model, artifact_path=\"xgb_model_baseline\")\n",
        "\n",
        "    # Tags setzen\n",
        "    mlflow.set_tag(\"stage\", \"baseline\")\n",
        "    mlflow.set_tag(\"model_type\", \"XGBoost\")\n",
        "\n",
        "    print(\"âœ… MLflow-Basislauf abgeschlossen!\")\n",
        "    print(\"ğŸ” Ergebnisse im MLflow-UI anzeigen mit:  mlflow ui\")"
      ],
      "metadata": {
        "id": "AHPi4WXbw-aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "# Dein Experiment-Name aus dem Code\n",
        "exp_name = \"XGBoost_Basislinie\"\n",
        "\n",
        "# Experiment-ID holen\n",
        "exp = mlflow.get_experiment_by_name(exp_name)\n",
        "\n",
        "# Alle Runs als DataFrame ziehen\n",
        "runs_df = mlflow.search_runs(\n",
        "    experiment_ids=[exp.experiment_id],\n",
        "    output_format=\"pandas\"\n",
        ")\n",
        "\n",
        "# Nur die wichtigsten Spalten zeigen\n",
        "cols = [\n",
        "    \"run_id\", \"tags.stage\", \"params.n_estimators\", \"params.learning_rate\",\n",
        "    \"params.max_depth\", \"metrics.MAE\", \"metrics.RMSE\", \"metrics.MAPE\"\n",
        "]\n",
        "display(runs_df[cols].sort_values(\"metrics.RMSE\"))\n"
      ],
      "metadata": {
        "id": "OH_A4gv23rw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Lauf â€“ MLflow fÃ¼r optimiertes XGBoost-Modell"
      ],
      "metadata": {
        "id": "zNij81QhxOm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Zweiter MLflow-Lauf: Optimiertes Modell\n",
        "with mlflow.start_run(run_name=\"Optimiertes-XGB\"):\n",
        "\n",
        "    # Trainiere Modell mit den besten Parametern aus RandomizedSearchCV\n",
        "    optimized_model = XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        n_estimators=best_params[\"n_estimators\"],\n",
        "        max_depth=best_params[\"max_depth\"],\n",
        "        learning_rate=best_params[\"learning_rate\"],\n",
        "        subsample=best_params[\"subsample\"],\n",
        "        colsample_bytree=best_params[\"colsample_bytree\"],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    optimized_model.fit(X_train, y_train)\n",
        "    y_pred_opt = optimized_model.predict(X_test)\n",
        "\n",
        "    # Berechne Metriken\n",
        "    metrics_opt = forecast_metrics(y_test, y_pred_opt)\n",
        "\n",
        "    # Logge Parameter und Metriken in MLflow\n",
        "    mlflow.log_params(best_params)\n",
        "    mlflow.log_metrics(metrics_opt)\n",
        "\n",
        "    # Erstelle Vergleichsdiagramm (tatsÃ¤chliche vs. vorhergesagte Werte)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(y_test.values[:200], label=\"Wahre Werte\", color=\"blue\")\n",
        "    plt.plot(y_pred_opt[:200], label=\"Optimierte Vorhersage\", color=\"green\")\n",
        "    plt.title(\"Optimiertes XGBoost-Modell: Wahr vs. Vorhergesagt\")\n",
        "    plt.xlabel(\"Zeitindex\")\n",
        "    plt.ylabel(\"Verkaufswert\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"optimized_forecast_plot.png\")\n",
        "\n",
        "    # Logge Diagramm und Modell\n",
        "    mlflow.log_artifact(\"optimized_forecast_plot.png\")\n",
        "    mlflow.xgboost.log_model(optimized_model, artifact_path=\"xgb_model_optimized\")\n",
        "\n",
        "    # Setze Tags (optional, fÃ¼r Ãœbersicht)\n",
        "    mlflow.set_tag(\"stage\", \"optimized\")\n",
        "    mlflow.set_tag(\"model_type\", \"XGBoost\")\n",
        "\n",
        "    print(\"âœ… Zweiter MLflow-Lauf abgeschlossen! (Optimiertes Modell)\")\n"
      ],
      "metadata": {
        "id": "_9UX_g0VxJd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“ŠVergleich Baseline vs. Optimiertes Modell: XGBoost"
      ],
      "metadata": {
        "id": "z28jymq04mPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Schritt werden die Ergebnisse des Basismodells und des optimierten XGBoost-Modells direkt miteinander verglichen.\n",
        "Dazu werden die gespeicherten MLflow-Runs geladen und die wichtigsten Metriken (z. B. RMSE, MAE, MAPE) ausgewertet.\n",
        "\n",
        "Die Balkengrafik zeigt die Unterschiede in der Modellleistung auf einen Blick â€“ insbesondere beim RMSE-Wert, der die Prognosegenauigkeit misst.\n",
        "So lÃ¤sst sich leicht erkennen, ob das Tuning tatsÃ¤chlich zu einer Verbesserung der VorhersagequalitÃ¤t gefÃ¼hrt hat.\n",
        "\n",
        "Ein wichtiger Schritt, um den Erfolg des Modelltrainings objektiv zu bewerten."
      ],
      "metadata": {
        "id": "6Q9TrvVMTdc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Experiment-Name aus deinen Runs\n",
        "exp_name = \"XGBoost_Basislinie\"\n",
        "\n",
        "# Experiment-ID holen\n",
        "exp = mlflow.get_experiment_by_name(exp_name)\n",
        "\n",
        "# Alle Runs laden\n",
        "runs_df = mlflow.search_runs(\n",
        "    experiment_ids=[exp.experiment_id],\n",
        "    output_format=\"pandas\"\n",
        ")\n",
        "\n",
        "# Nur wichtige Spalten anzeigen\n",
        "cols = [\n",
        "    \"tags.stage\",\n",
        "    \"params.n_estimators\",\n",
        "    \"params.learning_rate\",\n",
        "    \"params.max_depth\",\n",
        "    \"metrics.MAE\",\n",
        "    \"metrics.RMSE\",\n",
        "    \"metrics.MAPE\"\n",
        "]\n",
        "\n",
        "comparison_df = runs_df[cols].sort_values(\"metrics.RMSE\").reset_index(drop=True)\n",
        "display(comparison_df)\n"
      ],
      "metadata": {
        "id": "v6S8bn_w4qJZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visuelle GegenÃ¼berstellung (Barplot der Metriken)"
      ],
      "metadata": {
        "id": "jgI5zMMJ4wa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(comparison_df[\"tags.stage\"], comparison_df[\"metrics.RMSE\"], color=[\"orange\", \"green\"])\n",
        "plt.title(\"Vergleich: RMSE Baseline vs. Optimiert\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.xlabel(\"Modell\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jHnlUvtf4sOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Schritt wird aus allen gespeicherten MLflow-Runs automatisch das Modell mit dem besten RMSE-Wert ermittelt â€“ also jenes, das die genauesten Vorhersagen liefert.\n",
        "\n",
        "Der Code durchsucht die gespeicherten Ergebnisse, gibt die beste Run-ID aus und lÃ¤dt das entsprechende Modell direkt aus MLflow.\n",
        "Dadurch kannst du das leistungsstÃ¤rkste Modell jederzeit wiederverwenden, ohne es neu trainieren zu mÃ¼ssen.\n",
        "\n",
        "Ein wichtiger Schritt fÃ¼r Effizienz und Nachvollziehbarkeit im Modellmanagement."
      ],
      "metadata": {
        "id": "8n7QS845TpcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.xgboost\n",
        "import pandas as pd\n",
        "\n",
        "# Name deines MLflow-Experiments\n",
        "exp_name = \"XGBoost_Basislinie\"\n",
        "\n",
        "# Experiment holen\n",
        "exp = mlflow.get_experiment_by_name(exp_name)\n",
        "\n",
        "# Alle Runs abrufen\n",
        "runs_df = mlflow.search_runs(\n",
        "    experiment_ids=[exp.experiment_id],\n",
        "    output_format=\"pandas\"\n",
        ")\n",
        "\n",
        "# Besten Run anhand des niedrigsten RMSE finden\n",
        "best_run = runs_df.loc[runs_df[\"metrics.RMSE\"].idxmin()]\n",
        "best_run_id = best_run[\"run_id\"]\n",
        "\n",
        "print(\"ğŸ† Bestes Modell gefunden!\")\n",
        "print(f\"Stage: {best_run['tags.stage']}\")\n",
        "print(f\"RMSE: {best_run['metrics.RMSE']:.4f}\")\n",
        "print(f\"Run-ID: {best_run_id}\")\n"
      ],
      "metadata": {
        "id": "XL8mXOaX47cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modell aus MLflow laden\n",
        "model_uri = f\"runs:/{best_run_id}/xgb_model_optimized\"  # oder xgb_model_baseline, falls du das willst\n",
        "best_model = mlflow.xgboost.load_model(model_uri)\n",
        "\n",
        "print(\"âœ… Modell erfolgreich geladen!\")\n"
      ],
      "metadata": {
        "id": "CpeG6ocC48vL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}